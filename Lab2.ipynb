{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b0a7c6-1aaf-4fe3-a0ba-526994984867",
   "metadata": {
    "id": "36b0a7c6-1aaf-4fe3-a0ba-526994984867"
   },
   "source": [
    "## TI3160TU: Natural Language Processing - Ngram models Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda4b9d-a824-491a-b0f3-59a19c0b0924",
   "metadata": {
    "id": "4bda4b9d-a824-491a-b0f3-59a19c0b0924"
   },
   "source": [
    "In this hands-on lab, we will explore Ngram models. Ngram models are a simple form of language models (LMs). They assign probabilities to sequence of words based on a large corpus of data. In this lab, we will focus on three tasks related to Ngram models:\n",
    "\n",
    "1. **Extracting Ngrams from a corpus of data**\n",
    "2. **Calculating Ngram probabilities**\n",
    "3. **Generating text using Ngram models**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1c4c59-01e7-48fb-aeba-13f9ba958a13",
   "metadata": {
    "id": "ec1c4c59-01e7-48fb-aeba-13f9ba958a13"
   },
   "source": [
    "### 0. Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf0d0e7e-d149-4d3e-b279-10976a5c97b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cf0d0e7e-d149-4d3e-b279-10976a5c97b4",
    "outputId": "267860fa-b87b-4e02-931b-d8d1402f9a3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded Reddit comments! Our dataset includes 2215 Reddit comments!\n"
     ]
    }
   ],
   "source": [
    "# we need the library json as the reddit data is stored in line-delimited json objects\n",
    "# (one json object in each line, with each line representing a Reddit comment)\n",
    "import json\n",
    "\n",
    "# function to load all comment data into a list of strings\n",
    "# Input: the path of the file including our data\n",
    "# Output: a list of strings including the body of the Reddit comments\n",
    "def load_reddit_comment_data(data_directory):\n",
    "\n",
    "    comments_data = [] # list object that will store the loaded Reddit comments\n",
    "\n",
    "    # we first open the file that includes our dataset\n",
    "    with open(data_directory, 'r', encoding='utf-8') as f:\n",
    "        # iterate the file, reading it line by line\n",
    "        for line in f:\n",
    "            # load the data petraining to a line into a json object in memory\n",
    "            data = json.loads(line)\n",
    "\n",
    "            # append the comment if not removed\n",
    "            if data['body']!=\"[removed]\":\n",
    "                comments_data.append(data['body'])\n",
    "\n",
    "    # the method returns all the loaded Reddit comments\n",
    "    return comments_data\n",
    "\n",
    "# our data is stored in this file\n",
    "data_dir = './comments_TUDelft.ndjson'\n",
    "# lets load our dataset into memory\n",
    "reddit_data = load_reddit_comment_data(data_dir)\n",
    "print(\"Successfully loaded Reddit comments! Our dataset includes %d Reddit comments!\" %len(reddit_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc08c8d-4b5a-44dd-b064-8b41e7ba373e",
   "metadata": {
    "id": "8bc08c8d-4b5a-44dd-b064-8b41e7ba373e"
   },
   "source": [
    "### 1. Extracting Ngrams from a corpus of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8b9e9-09e1-493b-b00b-46d91b3193eb",
   "metadata": {
    "id": "57a8b9e9-09e1-493b-b00b-46d91b3193eb"
   },
   "source": [
    "We start by using the NLTK Python library to extract Ngrams from our Reddit dataset. First, we need to preprocess the dataset:\n",
    "1. Convert everything to lowercase\n",
    "2. Remove links\n",
    "3. Remove punctuation\n",
    "4. Tokenize posts into words\n",
    "5. Remove stopwords\n",
    "\n",
    "After preprocessing the dataset we will calculate Ngrams from our dataset and calculate the most popular Ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc95a1c-0645-47d9-9a3e-a6d1b3f2be51",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "ecc95a1c-0645-47d9-9a3e-a6d1b3f2be51",
    "outputId": "483c32e7-3967-48a3-d952-c500644b02d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 most popular ngrams in our dataset are...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ffc6ae82-25ac-47d2-9084-2a052cc5370b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bigram</th>\n",
       "      <th>#</th>\n",
       "      <th>Trigram</th>\n",
       "      <th>#</th>\n",
       "      <th>Fourgram</th>\n",
       "      <th>#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(tu, delft)</td>\n",
       "      <td>124</td>\n",
       "      <td>(first, year, material)</td>\n",
       "      <td>10</td>\n",
       "      <td>(education, student, affairs, esa)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(first, year)</td>\n",
       "      <td>56</td>\n",
       "      <td>(tu, delft, website)</td>\n",
       "      <td>8</td>\n",
       "      <td>(first, come, first, serve)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(dont, know)</td>\n",
       "      <td>48</td>\n",
       "      <td>(youre, gon, na)</td>\n",
       "      <td>7</td>\n",
       "      <td>(systematic, reasoning, logical, thinking)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(good, luck)</td>\n",
       "      <td>42</td>\n",
       "      <td>(high, school, diploma)</td>\n",
       "      <td>6</td>\n",
       "      <td>(see, delft, next, year)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(entrance, exam)</td>\n",
       "      <td>33</td>\n",
       "      <td>(grades, dont, matter)</td>\n",
       "      <td>5</td>\n",
       "      <td>(get, diploma, required, subjects)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(next, year)</td>\n",
       "      <td>33</td>\n",
       "      <td>(im, pretty, sure)</td>\n",
       "      <td>5</td>\n",
       "      <td>(mathematics, a2, mechanics, physics)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(thank, much)</td>\n",
       "      <td>33</td>\n",
       "      <td>(algorithms, data, structures)</td>\n",
       "      <td>5</td>\n",
       "      <td>(a2, mechanics, physics, a2)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(selection, procedure)</td>\n",
       "      <td>26</td>\n",
       "      <td>(hl, math, physics)</td>\n",
       "      <td>5</td>\n",
       "      <td>(contact, education, student, affairs)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(high, school)</td>\n",
       "      <td>26</td>\n",
       "      <td>(mathematics, a2, mechanics)</td>\n",
       "      <td>4</td>\n",
       "      <td>(710, decent, score, motivational)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(civil, engineering)</td>\n",
       "      <td>25</td>\n",
       "      <td>(education, student, affairs)</td>\n",
       "      <td>4</td>\n",
       "      <td>(decent, score, motivational, test)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffc6ae82-25ac-47d2-9084-2a052cc5370b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ffc6ae82-25ac-47d2-9084-2a052cc5370b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ffc6ae82-25ac-47d2-9084-2a052cc5370b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-2212552c-a150-4ff1-8740-354e77cb57ee\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2212552c-a150-4ff1-8740-354e77cb57ee')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-2212552c-a150-4ff1-8740-354e77cb57ee button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "                   Bigram    #                         Trigram   #  \\\n",
       "0             (tu, delft)  124         (first, year, material)  10   \n",
       "1           (first, year)   56            (tu, delft, website)   8   \n",
       "2            (dont, know)   48                (youre, gon, na)   7   \n",
       "3            (good, luck)   42         (high, school, diploma)   6   \n",
       "4        (entrance, exam)   33          (grades, dont, matter)   5   \n",
       "5            (next, year)   33              (im, pretty, sure)   5   \n",
       "6           (thank, much)   33  (algorithms, data, structures)   5   \n",
       "7  (selection, procedure)   26             (hl, math, physics)   5   \n",
       "8          (high, school)   26    (mathematics, a2, mechanics)   4   \n",
       "9    (civil, engineering)   25   (education, student, affairs)   4   \n",
       "\n",
       "                                     Fourgram  #  \n",
       "0          (education, student, affairs, esa)  3  \n",
       "1                 (first, come, first, serve)  3  \n",
       "2  (systematic, reasoning, logical, thinking)  3  \n",
       "3                    (see, delft, next, year)  3  \n",
       "4          (get, diploma, required, subjects)  2  \n",
       "5       (mathematics, a2, mechanics, physics)  2  \n",
       "6                (a2, mechanics, physics, a2)  2  \n",
       "7      (contact, education, student, affairs)  2  \n",
       "8          (710, decent, score, motivational)  2  \n",
       "9         (decent, score, motivational, test)  2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to preprocess the Reddit comments\n",
    "# Input: a string that includes a text corresponding to a Reddit comment\n",
    "# Output: a string with the preprocessed Reddit comment\n",
    "def preprocess(text):\n",
    "    text = text.lower()  # convert text to lower-case\n",
    "    text = re.sub('&gt;', '', text) # remove some special characters from the data &gt; corresponds to >\n",
    "    text = re.sub('&amp;', '', text) # remove some special characters from the data &amp; corresponds to &\n",
    "    text = re.sub(r'\\s+', ' ', text)  # eliminate duplicate whitespaces using regex\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', text)  # remove text in square brackets\n",
    "    text = re.sub(r'http\\S+', '', text)  # remove URLs\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)  # remove punctuation (keep only characters and numbers)\n",
    "    return text\n",
    "\n",
    "# run our function to preprocess all comments\n",
    "preprocessed_comments = [preprocess(comment) for comment in reddit_data]\n",
    "\n",
    "# Tokenize the comments and remove the stopwords\n",
    "all_words = [] # list of lists holding our dataset (each list corresponds to a comment and it includes the tokenized words)\n",
    "for comment in preprocessed_comments:\n",
    "    # tokenize the comments and remove stopwords\n",
    "    all_words.append([ w for w in word_tokenize(comment) if w not in stop_words])\n",
    "\n",
    "# calculate all ngrams for n=2, 3, and 4\n",
    "all_bigrams = []\n",
    "all_trigrams = []\n",
    "all_fourgrams = []\n",
    "\n",
    "# for each document\n",
    "for doc in all_words:\n",
    "    # calculate all ngrams with size 2 (i.e., bigrams) and then store them in our list holding all bigrams\n",
    "    all_bigrams.extend(list(ngrams(doc, 2)))\n",
    "    all_trigrams.extend(list(ngrams(doc, 3)))\n",
    "    all_fourgrams.extend(list(ngrams(doc, 4)))\n",
    "\n",
    "# we use the Counter class from Collections to find the top N most occurring Ngrams in our dataset\n",
    "top_bigrams = Counter(all_bigrams).most_common(10)\n",
    "top_trigrams = Counter(all_trigrams).most_common(10)\n",
    "top_fourgrams = Counter(all_fourgrams).most_common(10)\n",
    "\n",
    "# lets present the most occurring Ngrams in a nice table using Pandas\n",
    "top_bigrams_df = pd.DataFrame(top_bigrams, columns =['Bigram', '#']) # create DataFrame for bigrams\n",
    "top_trigrams_df = pd.DataFrame(top_trigrams, columns=['Trigram', '#']) # create DataFrame for trigrams\n",
    "top_fourgrams_df = pd.DataFrame(top_fourgrams, columns=['Fourgram', '#']) # create DataFrame for fourgrams\n",
    "ngrams_df = pd.concat([top_bigrams_df, top_trigrams_df, top_fourgrams_df], axis=1) # concatenate all to a single datafrme\n",
    "\n",
    "print(\"The top 10 most popular ngrams in our dataset are...\")\n",
    "ngrams_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c51b92d-1dbb-4285-b623-0008ed85916c",
   "metadata": {
    "id": "1c51b92d-1dbb-4285-b623-0008ed85916c"
   },
   "source": [
    "### 2. Calculating Ngram probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea84acd3-6f4f-4598-9d1c-faca203549b2",
   "metadata": {
    "id": "ea84acd3-6f4f-4598-9d1c-faca203549b2"
   },
   "outputs": [],
   "source": [
    "bigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "trigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "fourgram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "# Bigrams\n",
    "for bigram in all_bigrams:\n",
    "    w1, w2 = bigram\n",
    "    bigram_model[w1][w2] += 1\n",
    "\n",
    "# Normalize bigram counts to get probabilities\n",
    "for w1 in bigram_model:\n",
    "    total_count = float(sum(bigram_model[w1].values()))\n",
    "    for w2 in bigram_model[w1]:\n",
    "        bigram_model[w1][w2] /= total_count\n",
    "\n",
    "# Trigrams\n",
    "for trigram in all_trigrams:\n",
    "    w1, w2, w3 = trigram\n",
    "    trigram_model[(w1, w2)][w3] += 1\n",
    "\n",
    "# Normalize trigram counts to get probabilities\n",
    "for w1_w2 in trigram_model:\n",
    "    total_count = float(sum(trigram_model[w1_w2].values()))\n",
    "    for w3 in trigram_model[w1_w2]:\n",
    "        trigram_model[w1_w2][w3] /= total_count\n",
    "\n",
    "# Fourgrams\n",
    "for fourgram in all_fourgrams:\n",
    "    w1, w2, w3, w4 = fourgram\n",
    "    fourgram_model[(w1, w2, w3)][w4] += 1\n",
    "\n",
    "# Normalize fourgram counts to get probabilities\n",
    "for w1_w2_w3 in fourgram_model:\n",
    "    total_count = float(sum(fourgram_model[w1_w2_w3].values()))\n",
    "    for w4 in fourgram_model[w1_w2_w3]:\n",
    "        fourgram_model[w1_w2_w3][w4] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81be5438-eb24-428d-8b7c-9e6b932f6005",
   "metadata": {
    "id": "81be5438-eb24-428d-8b7c-9e6b932f6005"
   },
   "source": [
    "### 3. Generating text using Ngram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1941d3d-0149-4e84-abc3-4d27cf351877",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1941d3d-0149-4e84-abc3-4d27cf351877",
    "outputId": "f399f5ef-abde-48ae-f096-8acbfb857010"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated with bigram model:  tu delft university laptop doesnt come study programme obligatory aissce indian\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# function that uses a bigram model to generate some text\n",
    "# Input: A bigram model, a starting word, and the length of the sentence that we want to generate\n",
    "# Output: A string that corresponds to a sentence that is generated based on the bigram probabilities\n",
    "def generate_text_bigram(model, start_word, num_words):\n",
    "    # Initialize the current word as the start word\n",
    "    current_word = start_word\n",
    "\n",
    "    # Initialize the sentence as a list containing the start word\n",
    "    sentence = [current_word]\n",
    "\n",
    "    # Loop over the desired number of words\n",
    "    for _ in range(num_words):\n",
    "        # Check if the current word exists in our model\n",
    "        if model[current_word]:\n",
    "            # Get the list of potential next words\n",
    "            next_words = list(model[current_word].keys())\n",
    "\n",
    "            # Get the list of probabilities corresponding to the next words\n",
    "            next_word_probs = list(model[current_word].values())\n",
    "\n",
    "            # Randomly choose a next word based on the probabilities\n",
    "            # np.random.choice selects an item from \"next_words\" list taking into account their corresponding probability distribution from \"next_word_probs\"\n",
    "            next_word = np.random.choice(next_words, p=next_word_probs)\n",
    "\n",
    "            # Append this word to our sentence\n",
    "            sentence.append(next_word)\n",
    "\n",
    "            # Update the current word to be the word we just added to the sentence\n",
    "            current_word = next_word\n",
    "        else:\n",
    "            # If the current word isn't in our model (this would happen if the word didn't have any following word in the training data),\n",
    "            # break the loop and end the sentence\n",
    "            break\n",
    "\n",
    "    # Join the words in the sentence list with spaces in between to form a string sentence\n",
    "    return \" \".join(sentence)\n",
    "\n",
    "# Generate text\n",
    "print(\"Generated with bigram model: \", generate_text_bigram(bigram_model, \"tu\", 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f105cd6-44bf-4945-a76b-71e747add146",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f105cd6-44bf-4945-a76b-71e747add146",
    "outputId": "6bdc74eb-df63-4231-e23a-d5bc059ad187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated with trigram model:  tu delft pages lot apply case x etc questions would nice type\n",
      "Generated with fourgram model:  tu delft university provide incredibly creative surrounding\n"
     ]
    }
   ],
   "source": [
    "# function to generate text using a Trigram/Fourgram model\n",
    "# Input: A Trigram/Fourgram model, a starting word, and the length of the sentence that we want to generate\n",
    "# Output: A string that corresponds to a sentence that is generated based on the Ngram probabilities\n",
    "def generate_text_trigram_fourgram(model, start_words, num_words):\n",
    "    # Start_words should be a tuple of words of length matching the model order (i.e., for trigram model we should provide two words, for fourgram three words, etc.)\n",
    "    current_words = start_words\n",
    "\n",
    "    # Initialize the sentence as a list containing all the start words\n",
    "    sentence = list(current_words)\n",
    "\n",
    "    # We'll use the length of the start_sequence to determine the order of the model (bigram, trigram, etc.)\n",
    "    ngram_order = len(start_words)\n",
    "\n",
    "    # Loop over the desired number of words\n",
    "    for _ in range(num_words):\n",
    "\n",
    "        # Check if the current words exists in our model\n",
    "        if model[current_words]:\n",
    "\n",
    "            # Get the list of potential next words\n",
    "            next_words = list(model[current_words].keys())\n",
    "\n",
    "            # Get the list of probabilities corresponding to the next words\n",
    "            next_word_probs = list(model[current_words].values())\n",
    "\n",
    "            # Randomly choose a next word based on the probabilities\n",
    "            # np.random.choice selects an item from \"next_words\" list taking into account their corresponding probability distribution from \"next_word_probs\"\n",
    "            next_word = np.random.choice(next_words, p=next_word_probs)\n",
    "\n",
    "            # Append this word to our sentence\n",
    "            sentence.append(next_word)\n",
    "\n",
    "            # Update the current words so that they are the last Ngram order words in the generated sentence\n",
    "            current_words = tuple(sentence[-ngram_order:])\n",
    "        else:\n",
    "            # If the current word isn't in our model (this would happen if the word didn't have any following word in the training data),\n",
    "            # break the loop and end the sentence\n",
    "            break\n",
    "\n",
    "    # Join the words in the sentence list with spaces in between to form a string sentence\n",
    "    return \" \".join(sentence)\n",
    "\n",
    "# Generate text\n",
    "print(\"Generated with trigram model: \", generate_text_trigram_fourgram(trigram_model, (\"tu\", \"delft\"), 10))\n",
    "print(\"Generated with fourgram model: \", generate_text_trigram_fourgram(fourgram_model, (\"tu\", \"delft\", \"university\"), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d57c90-e2cc-41d3-b69b-9d870fdf71e6",
   "metadata": {
    "id": "d2d57c90-e2cc-41d3-b69b-9d870fdf71e6"
   },
   "source": [
    "##### What do you observe from the generated outputs from the bigram, trigram, and fourgram models? What model you think generates the more coherent output? Why is that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef4748-5d35-4850-b1b6-a54c05b35763",
   "metadata": {
    "id": "f8ef4748-5d35-4850-b1b6-a54c05b35763"
   },
   "source": [
    "## Calculating Sentence Probabilities\n",
    "\n",
    "Having some bigrams, trigrams, and fourgrams models trained on our Reddit corpus, we can calculate the probabilities of a full phrase or sentence appearing. This is equivalent to the conditional probabilities of the n-1 words before the current word. E.g., for the bigram model, is the conditional probability of a word appearing, when considering only the previous word. Lets see how we can calculate sentence probabilities, first with the bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bea191a-90c5-4f3c-8e51-7b8b9112f852",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bea191a-90c5-4f3c-8e51-7b8b9112f852",
    "outputId": "0827b273-5e86-4e58-e408-44fe611260e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability for tu delft using bigram model = 0.789809\n"
     ]
    }
   ],
   "source": [
    "# function to calculate the sentence probability from a bigram model\n",
    "# Input: a sentence and the bigram model\n",
    "# Output: the sentence probability within the bigram model\n",
    "def calculate_sentence_probability_bigram(sentence, model):\n",
    "    # Convert input sentence to a list of words\n",
    "    sentence = sentence.split(\" \")\n",
    "\n",
    "    # Initialize probability\n",
    "    probability = 1\n",
    "\n",
    "    # Loop over the sentence. For each word, get its probability and multiply it to the current probability\n",
    "    for i in range(1, len(sentence)):\n",
    "        # Get the preceding word and current word\n",
    "        preceding_word = sentence[i-1]\n",
    "        current_word = sentence[i]\n",
    "\n",
    "        # If the preceding word is not in the model or the current word is not in the preceding word's distribution,\n",
    "        # the probability is 0\n",
    "        if preceding_word not in model or current_word not in model[preceding_word]:\n",
    "            return 0\n",
    "\n",
    "        # Multiply the current probability with the current word's probability\n",
    "        probability *= model[preceding_word][current_word]\n",
    "\n",
    "    # return the calculated probability\n",
    "    return probability\n",
    "\n",
    "# lets test it with some toy sentence\n",
    "sentence = \"tu delft\"\n",
    "print(\"The probability for %s using bigram model = %f\" %(sentence, calculate_sentence_probability_bigram(sentence, bigram_model) ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d15d7e-9c64-45ca-8b16-79db5f865b30",
   "metadata": {
    "id": "f1d15d7e-9c64-45ca-8b16-79db5f865b30"
   },
   "source": [
    "This means that when given the word \"tu\", the probability of the next word being \"delft\" is almost 79% in our bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2641d728-3a17-43be-8395-948c04126147",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2641d728-3a17-43be-8395-948c04126147",
    "outputId": "2c9c28ac-abf0-49ad-defb-fb9e0a0e7130"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability for tu delft university using bigram model = 0.009148\n"
     ]
    }
   ],
   "source": [
    "sentence = \"tu delft university\"\n",
    "print(\"The probability for %s using bigram model = %f\" %(sentence, calculate_sentence_probability_bigram(sentence, bigram_model) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05f7f3-a7fa-4ea3-bf60-27acd3aadc25",
   "metadata": {
    "id": "2f05f7f3-a7fa-4ea3-bf60-27acd3aadc25"
   },
   "source": [
    "This means that when given the word \"tu\", the probability of the next words being \"delft university\" is less than 1% in our bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6891a315-4163-4759-9b06-b6f24192ac2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6891a315-4163-4759-9b06-b6f24192ac2f",
    "outputId": "28430fa7-9c6c-48b2-9753-d5ab5b6b8a49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability for tu eindhoven using bigram model = 0.038217\n"
     ]
    }
   ],
   "source": [
    "sentence = \"tu eindhoven\"\n",
    "print(\"The probability for %s using bigram model = %f\" %(sentence, calculate_sentence_probability_bigram(sentence, bigram_model) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb530cf8-3891-429d-aa74-88240f0fbf5c",
   "metadata": {
    "id": "bb530cf8-3891-429d-aa74-88240f0fbf5c"
   },
   "source": [
    "This means that when given the word \"tu\", the probability of the next word being \"eindhoven\" is less than 4% in our bigram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec1b0c3d-a2fa-4989-a677-24b1b06a53cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ec1b0c3d-a2fa-4989-a677-24b1b06a53cc",
    "outputId": "7134e59d-d878-4a5f-b6ce-f0f5f620ae86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability for tu eindhoven university using bigram model = 0.000000\n"
     ]
    }
   ],
   "source": [
    "sentence = \"tu eindhoven university\"\n",
    "print(\"The probability for %s using bigram model = %f\" %(sentence, calculate_sentence_probability_bigram(sentence, bigram_model) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88579c-53ba-49ba-981b-71ab32639271",
   "metadata": {
    "id": "8f88579c-53ba-49ba-981b-71ab32639271"
   },
   "source": [
    "### What do you observe from these probabilities?\n",
    "\n",
    "##### Think about the occurrences of the words in the corpus (tu delft vs tu eindhoven). Also, why is the \"tu eindhoven university\" sentence probability zero? How can we solve this issue? Also, how do the probabilities change when we add more words? Think about the smoothing techniques and log probability calculation as we see in the lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede03a4a-6f58-4c61-bff9-b10f0dbcc917",
   "metadata": {
    "id": "ede03a4a-6f58-4c61-bff9-b10f0dbcc917"
   },
   "source": [
    "## Exercise: Write code to implement trigram and fourgram models. Then check how the probabilities of n-grams like \"tu delft university\" change. What do you observe when comparing the probability of \"tu delft university\" for 2-gram and 3-gram model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eba384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6172a99",
   "metadata": {
    "id": "f6172a99"
   },
   "source": [
    "## TI3160TU: Natural Language Processing - Ngram models lab -- END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc655960",
   "metadata": {
    "id": "dc655960"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
